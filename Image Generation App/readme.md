Hereâ€™s your fancy, **visually styled and formatted** version â€” great for publishing on GitHub, Notion, a blog, or as a professional project showcase:

---

# ðŸ§  **Voice-Enabled AI Agent (with Tool Integration using LangGraph)**

A **Flask-based web application** that connects a **LangGraph-based AI Agent** with an interactive frontend using **SocketIO**.
It leverages **Groq's LLaMA 3** model, supports tool usage (e.g., image generation), and integrates **OpenAI Whisper** for **speech-to-text interaction**.

---

## ðŸš€ **Features**

* ðŸ” **Real-time interaction** with LLM agent via **WebSockets** (`Flask-SocketIO`)
* ðŸ§© **Reasoning loop** via **LangGraph**, enabling conditional tool usage
* ðŸ–¼ï¸ **Multi-modal outputs** â€“ including **image generation** via tools like Gemini or Stable Diffusion
* ðŸ”Œ **MCP Client integration** to plug in multiple tools seamlessly
* âš™ï¸ **Modular & production-ready** with async support and extensibility

---

## ðŸ› ï¸ **Technologies Used**

* `Flask` + `Flask-SocketIO` for backend and real-time updates
* `LangGraph` for stateful multi-turn agent workflows
* `Groq's LLaMA 3` via `langchain_groq`
* `langchain-mcp-adapters` for tool orchestration
* `dotenv` for API/config management
* `OpenAI Whisper` (optional) for **voice-based interaction**

---

## ðŸ“‚ **Folder Structure**

```
.
â”œâ”€â”€ app.py                        # Main Flask app
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html               # Frontend template
â”œâ”€â”€ static/                      # For images, CSS, JS
â”œâ”€â”€ .env                         # API keys & config
â”œâ”€â”€ gemini_image_generator.py 
|__ stable_diffusion_server.py   # (Tool server) Image generator tool
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ **Setup Instructions**

### 1. ðŸ”‘ Clone the repository and install dependencies

```bash
git clone https://github.com/yourname/ai-agent-app.git
cd ai-agent-app
pip install -r requirements.txt
```

---

### 2. ðŸ” Setup `.env` file

Create a `.env` file with the following content:

```env
GROQ_API_KEY=your_groq_api_key_here
OPENAI_API_KEY=your_openai_key_if_using_whisper_or_other_tools
```

> âœ… You can get a **free Groq API key** from [Groq Cloud](https://console.groq.com/).

---

### â–¶ï¸ Run the Agent

```bash
python app.py
```

ðŸ”— Your server will be live at: [http://localhost:5000](http://localhost:5000)

---

## ðŸ§° **Switching from Gemini to Stable Diffusion**

The app uses **Gemini** by default for image generation (`gemini_image_generator.py`).

To switch to **Stable Diffusion**, modify the **MCP client config** in `app.py`.

### ðŸ”„ Current Configuration:

```python
client = MultiServerMCPClient(
    {
        "image_generation": {
            "command": "python",
            "args": ["gemini_image_generator.py"],
            "transport": "stdio"
        }
    }
)
```

### âœ… Update To:

```python
client = MultiServerMCPClient(
    {
        "image_generation": {
            "command": "python",
            "args": ["stable_diffusion_server.py"],
            "transport": "stdio"
        }
    }
)
```

> ðŸ“Œ Make sure `stable_diffusion_server.py` is implemented and follows **MCP-style messaging**.

---

## ðŸŽ¤ **Voice Integration (Optional)**

To enable **voice interaction**:

* Use OpenAI Whisper to transcribe user speech.
* Send transcribed text to the chat endpoint (`/message`) via frontend.
* Respond to voice inputs like normal messages, with optional visual or tool responses.


